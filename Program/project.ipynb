{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1wUuWx3-NEvwwkUCPkbQT84IKomm9bgtd","authorship_tag":"ABX9TyPcfMO5Fo+JmOX9n8x3MMfi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":107},"id":"g_PrHCFBYTPa","executionInfo":{"status":"ok","timestamp":1751011470091,"user_tz":-330,"elapsed":6930,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}},"outputId":"a6eb9569-e352-4655-cf4d-35b0d303acd5"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-71938b93-ab72-4c5a-b8bb-e1b48d78a721\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-71938b93-ab72-4c5a-b8bb-e1b48d78a721\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle (1).json to kaggle (1).json\n","cp: cannot stat 'kaggle.json': No such file or directory\n","chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"]}],"source":["from google.colab import files\n","files.upload()\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"]},{"cell_type":"code","source":["!mkdir -p ~/.kaggle\n","!cp \"kaggle (1).json\" ~/.kaggle/kaggle.json\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n"],"metadata":{"id":"pf2z5ZfzazW3","executionInfo":{"status":"ok","timestamp":1751011510476,"user_tz":-330,"elapsed":316,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!kaggle datasets download -d  phucthaiv02/butterfly-image-classification\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gTL77Vh6a1Uf","executionInfo":{"status":"ok","timestamp":1751011576073,"user_tz":-330,"elapsed":3929,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}},"outputId":"a8b55793-4265-4f32-c84c-dd8bb4dac40d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset URL: https://www.kaggle.com/datasets/phucthaiv02/butterfly-image-classification\n","License(s): CC0-1.0\n","Downloading butterfly-image-classification.zip to /content\n"," 52% 117M/226M [00:00<00:00, 1.23GB/s]\n","100% 226M/226M [00:00<00:00, 808MB/s] \n"]}]},{"cell_type":"code","source":["!unzip -q butterfly-image-classification.zip -d '/content/drive/MyDrive/datasets'"],"metadata":{"id":"0-9hzDPnbGUY","executionInfo":{"status":"ok","timestamp":1751011876696,"user_tz":-330,"elapsed":95958,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","strategy = tf.distribute.get_strategy()\n","print(\"Using:\", tf.config.list_physical_devices())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4DcXvo6hcgJT","executionInfo":{"status":"ok","timestamp":1751011963064,"user_tz":-330,"elapsed":7833,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}},"outputId":"e68222d1-9833-4149-8277-0516474c9737"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]}]},{"cell_type":"code","source":["!cp -r /content/drive/MyDrive/datasets/train /content/train_local"],"metadata":{"id":"dcGZrO80clg6","executionInfo":{"status":"ok","timestamp":1751011994964,"user_tz":-330,"elapsed":10039,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n","from tensorflow.keras.layers import Flatten, Dense, Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"],"metadata":{"id":"mEBet4FKdJA8","executionInfo":{"status":"ok","timestamp":1751012167617,"user_tz":-330,"elapsed":5,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv(\"/content/drive/MyDrive/datasets/Training_set.csv\")\n","test_df = pd.read_csv(\"/content/drive/MyDrive/datasets/Testing_set.csv\")\n","\n","print(\"Unique classes:\", train_df['label'].nunique())\n","print(train_df['label'].value_counts())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H9flWlHBdO6y","executionInfo":{"status":"ok","timestamp":1751012181027,"user_tz":-330,"elapsed":19,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}},"outputId":"dd30b70e-81d2-4c3f-8073-a3d0437a2c9d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique classes: 75\n","label\n","MOURNING CLOAK    131\n","SLEEPY ORANGE     107\n","ATALA             100\n","BROWN SIPROETA     99\n","SCARCE SWALLOW     97\n","                 ... \n","AMERICAN SNOOT     74\n","GOLD BANDED        73\n","MALACHITE          73\n","CRIMSON PATCH      72\n","WOOD SATYR         71\n","Name: count, Length: 75, dtype: int64\n"]}]},{"cell_type":"code","source":["train_df.head(\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"VpYxXzKIeCzV","executionInfo":{"status":"ok","timestamp":1751012371270,"user_tz":-330,"elapsed":46,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}},"outputId":"04f792a5-782b-4c2a-eaf7-a8b91c97c1ec"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      filename                     label\n","0  Image_1.jpg          SOUTHERN DOGFACE\n","1  Image_2.jpg                    ADONIS\n","2  Image_3.jpg            BROWN SIPROETA\n","3  Image_4.jpg                   MONARCH\n","4  Image_5.jpg  GREEN CELLED CATTLEHEART"],"text/html":["\n","  <div id=\"df-0b8a811b-2e89-4162-b2db-fee85fe0dc2e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Image_1.jpg</td>\n","      <td>SOUTHERN DOGFACE</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Image_2.jpg</td>\n","      <td>ADONIS</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Image_3.jpg</td>\n","      <td>BROWN SIPROETA</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Image_4.jpg</td>\n","      <td>MONARCH</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Image_5.jpg</td>\n","      <td>GREEN CELLED CATTLEHEART</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b8a811b-2e89-4162-b2db-fee85fe0dc2e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0b8a811b-2e89-4162-b2db-fee85fe0dc2e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0b8a811b-2e89-4162-b2db-fee85fe0dc2e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-fcbbd0e2-c347-4fa2-8559-2681b5f8e6ab\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fcbbd0e2-c347-4fa2-8559-2681b5f8e6ab')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-fcbbd0e2-c347-4fa2-8559-2681b5f8e6ab button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Image_2.jpg\",\n          \"Image_5.jpg\",\n          \"Image_3.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ADONIS\",\n          \"GREEN CELLED CATTLEHEART\",\n          \"BROWN SIPROETA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["train_datagen = ImageDataGenerator(\n","    preprocessing_function=preprocess_input,\n","    validation_split=0.2\n",")\n","\n","train_gen = train_datagen.flow_from_dataframe(\n","    train_df,\n","    directory=\"/content/drive/MyDrive/datasets/train\",\n","    x_col=\"filename\",\n","    y_col=\"label\",\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='training',\n","    shuffle=True\n",")\n","\n","val_gen = train_datagen.flow_from_dataframe(\n","    train_df,\n","    directory=\"/content/drive/MyDrive/datasets/train\",\n","    x_col=\"filename\",\n","    y_col=\"label\",\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='validation',\n","    shuffle=False\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kKgQVnP0dY9z","executionInfo":{"status":"ok","timestamp":1751012424538,"user_tz":-330,"elapsed":1595,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}},"outputId":"0c9e6304-b286-42c1-f4dc-76ebf68b5a96"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 3113 validated image filenames belonging to 75 classes.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 2608 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Found 778 validated image filenames belonging to 75 classes.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 2608 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","for layer in base_model.layers:\n","    layer.trainable = False  # Freeze base layers\n","\n","x = Flatten()(base_model.output)\n","x = Dense(256, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","output = Dense(len(train_gen.class_indices), activation='softmax')(x)\n","\n","model = Model(inputs=base_model.input, outputs=output)\n","model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"-eDypts8deE8","executionInfo":{"status":"ok","timestamp":1751012464660,"user_tz":-330,"elapsed":248,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/model.keras\",\n","                             monitor='val_accuracy',\n","                             save_best_only=True,\n","                             verbose=1)\n"],"metadata":{"id":"asoC5F3beeKt","executionInfo":{"status":"ok","timestamp":1751012482449,"user_tz":-330,"elapsed":6,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["early_stop = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n","history = model.fit(\n","    train_gen,\n","    validation_data=val_gen,\n","    epochs=10,\n","    callbacks=[checkpoint, early_stop]\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AkOMsI5celvH","executionInfo":{"status":"ok","timestamp":1751013865095,"user_tz":-330,"elapsed":1362363,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}},"outputId":"24bef777-32e1-4693-be50-1b71caec97d9"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - accuracy: 0.0302 - loss: 19.6992\n","Epoch 1: val_accuracy improved from -inf to 0.05913, saving model to /content/drive/MyDrive/model.keras\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1120s\u001b[0m 11s/step - accuracy: 0.0302 - loss: 19.6022 - val_accuracy: 0.0591 - val_loss: 4.2143\n","Epoch 2/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.0574 - loss: 4.0823\n","Epoch 2: val_accuracy improved from 0.05913 to 0.10283, saving model to /content/drive/MyDrive/model.keras\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 208ms/step - accuracy: 0.0575 - loss: 4.0819 - val_accuracy: 0.1028 - val_loss: 4.0245\n","Epoch 3/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.1159 - loss: 3.7284\n","Epoch 3: val_accuracy improved from 0.10283 to 0.14524, saving model to /content/drive/MyDrive/model.keras\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 233ms/step - accuracy: 0.1158 - loss: 3.7287 - val_accuracy: 0.1452 - val_loss: 3.8692\n","Epoch 4/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.1504 - loss: 3.4669\n","Epoch 4: val_accuracy improved from 0.14524 to 0.21208, saving model to /content/drive/MyDrive/model.keras\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 242ms/step - accuracy: 0.1505 - loss: 3.4668 - val_accuracy: 0.2121 - val_loss: 3.6394\n","Epoch 5/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.2091 - loss: 3.2585\n","Epoch 5: val_accuracy improved from 0.21208 to 0.24422, saving model to /content/drive/MyDrive/model.keras\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 235ms/step - accuracy: 0.2093 - loss: 3.2580 - val_accuracy: 0.2442 - val_loss: 3.4291\n","Epoch 6/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.2810 - loss: 2.8866\n","Epoch 6: val_accuracy improved from 0.24422 to 0.29177, saving model to /content/drive/MyDrive/model.keras\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 233ms/step - accuracy: 0.2810 - loss: 2.8865 - val_accuracy: 0.2918 - val_loss: 3.2198\n","Epoch 7/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.3353 - loss: 2.6443\n","Epoch 7: val_accuracy improved from 0.29177 to 0.35090, saving model to /content/drive/MyDrive/model.keras\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 238ms/step - accuracy: 0.3353 - loss: 2.6442 - val_accuracy: 0.3509 - val_loss: 3.0287\n","Epoch 8/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.3737 - loss: 2.4344\n","Epoch 8: val_accuracy improved from 0.35090 to 0.38432, saving model to /content/drive/MyDrive/model.keras\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 247ms/step - accuracy: 0.3737 - loss: 2.4346 - val_accuracy: 0.3843 - val_loss: 2.8867\n","Epoch 9/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.4152 - loss: 2.2748\n","Epoch 9: val_accuracy improved from 0.38432 to 0.40360, saving model to /content/drive/MyDrive/model.keras\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 216ms/step - accuracy: 0.4154 - loss: 2.2741 - val_accuracy: 0.4036 - val_loss: 2.8105\n","Epoch 10/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.4620 - loss: 2.0143\n","Epoch 10: val_accuracy improved from 0.40360 to 0.43316, saving model to /content/drive/MyDrive/model.keras\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 240ms/step - accuracy: 0.4621 - loss: 2.0143 - val_accuracy: 0.4332 - val_loss: 2.6038\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","\n","model = load_model(\"/content/drive/MyDrive/model.keras\")"],"metadata":{"id":"elxpGVWcpbJO","executionInfo":{"status":"ok","timestamp":1751015378129,"user_tz":-330,"elapsed":550,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.optimizers import Adam\n","\n","model.compile(\n","    optimizer=Adam(learning_rate=1e-4),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n"],"metadata":{"id":"hf_iTC9npm8-","executionInfo":{"status":"ok","timestamp":1751015421011,"user_tz":-330,"elapsed":49,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","\n","checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/model.keras\", monitor='val_accuracy', save_best_only=True, verbose=1)\n","early_stop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n","lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, min_lr=1e-7)\n","\n","history = model.fit(\n","    train_gen,\n","    validation_data=val_gen,\n","    epochs=10,\n","    callbacks=[checkpoint, early_stop, lr_reduce]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HdWF4qO4pvzo","executionInfo":{"status":"ok","timestamp":1751017187942,"user_tz":-330,"elapsed":253488,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}},"outputId":"629da0c9-8f37-4d1e-ee38-79204c8cd00a"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.8261 - loss: 0.5535\n","Epoch 1: val_accuracy improved from -inf to 0.71851, saving model to /content/drive/MyDrive/model.keras\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 242ms/step - accuracy: 0.8261 - loss: 0.5537 - val_accuracy: 0.7185 - val_loss: 1.6098 - learning_rate: 1.2500e-05\n","Epoch 2/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.8500 - loss: 0.4549\n","Epoch 2: val_accuracy did not improve from 0.71851\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 217ms/step - accuracy: 0.8500 - loss: 0.4550 - val_accuracy: 0.7172 - val_loss: 1.6354 - learning_rate: 1.2500e-05\n","Epoch 3/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8316 - loss: 0.5423\n","Epoch 3: val_accuracy did not improve from 0.71851\n","\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 223ms/step - accuracy: 0.8317 - loss: 0.5419 - val_accuracy: 0.7134 - val_loss: 1.6581 - learning_rate: 1.2500e-05\n","Epoch 4/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.8405 - loss: 0.4983\n","Epoch 4: val_accuracy improved from 0.71851 to 0.71979, saving model to /content/drive/MyDrive/model.keras\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 226ms/step - accuracy: 0.8406 - loss: 0.4983 - val_accuracy: 0.7198 - val_loss: 1.6449 - learning_rate: 6.2500e-06\n","Epoch 5/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8433 - loss: 0.4944\n","Epoch 5: val_accuracy did not improve from 0.71979\n","\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 226ms/step - accuracy: 0.8433 - loss: 0.4943 - val_accuracy: 0.7134 - val_loss: 1.6373 - learning_rate: 6.2500e-06\n","Epoch 6/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8502 - loss: 0.4506\n","Epoch 6: val_accuracy did not improve from 0.71979\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 222ms/step - accuracy: 0.8501 - loss: 0.4509 - val_accuracy: 0.7159 - val_loss: 1.6444 - learning_rate: 3.1250e-06\n","Epoch 7/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8359 - loss: 0.5056\n","Epoch 7: val_accuracy did not improve from 0.71979\n","\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - accuracy: 0.8359 - loss: 0.5056 - val_accuracy: 0.7172 - val_loss: 1.6481 - learning_rate: 3.1250e-06\n","Epoch 8/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.8555 - loss: 0.4676\n","Epoch 8: val_accuracy did not improve from 0.71979\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 224ms/step - accuracy: 0.8555 - loss: 0.4676 - val_accuracy: 0.7147 - val_loss: 1.6481 - learning_rate: 1.5625e-06\n","Epoch 9/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.8387 - loss: 0.4895\n","Epoch 9: val_accuracy did not improve from 0.71979\n","\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - accuracy: 0.8387 - loss: 0.4894 - val_accuracy: 0.7172 - val_loss: 1.6501 - learning_rate: 1.5625e-06\n"]}]},{"cell_type":"code","source":["datagen = ImageDataGenerator(\n","    preprocessing_function=preprocess_input,\n",")\n","\n","test_gen = train_datagen.flow_from_dataframe(\n","    test_df,\n","    directory=\"/content/drive/MyDrive/datasets/test\",\n","    x_col='filename',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode=None,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hS1TiIGLsIfC","executionInfo":{"status":"ok","timestamp":1751016063214,"user_tz":-330,"elapsed":412,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}},"outputId":"795d6e86-90bf-4a56-dcb3-217acd750076"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2786 validated image filenames.\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","img = image.load_img('/content/drive/MyDrive/test.jpg', target_size=(224, 224))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = preprocess_input(x)\n","\n","preds = model.predict(x)\n","predicted_class = np.argmax(preds)\n","class_labels = list(train_gen.class_indices.keys())\n","print(\"Predicted class:\", class_labels[predicted_class], f\"(confidence: {np.max(preds):.2f})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XTbBP74ssNCI","executionInfo":{"status":"ok","timestamp":1751016188679,"user_tz":-330,"elapsed":3364,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}},"outputId":"bd4ac754-35c7-49ca-ac20-1793c877d7f0"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","Predicted class: AN 88 (confidence: 1.00)\n"]}]},{"cell_type":"code","source":["import json\n","with open(\"class_indices.json\", \"w\") as f:\n","    json.dump(train_gen.class_indices, f)\n"],"metadata":{"id":"RnFf3DWvs984","executionInfo":{"status":"ok","timestamp":1751016270986,"user_tz":-330,"elapsed":2,"user":{"displayName":"Tilak Chodagiri","userId":"08437516987976839075"}}},"execution_count":23,"outputs":[]}]}